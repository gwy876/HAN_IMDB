{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB_LSTM_HAN_complete - 94.73%\n",
    "- 181204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data : imdb unzip하여 다운\n",
    "# wget https://www.kaggle.com/c/word2vec-nlp-tutorial/download/labeledTrainData.tsv\n",
    "# 이름바꾸고 unzip\n",
    "\n",
    "# HAN 코드 출처\n",
    "# https://www.kaggle.com/sermakarevich/hierarchical-attention-network/comments\n",
    "# https://richliao.github.io/supervised/classification/2016/12/26/textclassifier-HATN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from nltk import tokenize\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding, RepeatVector, Permute, Multiply, Lambda, BatchNormalization, LeakyReLU\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, merge, Dropout, LSTM, CuDNNLSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler, Callback, ModelCheckpoint\n",
    "\n",
    "from keras.optimizers import Adam, Adadelta, SGD\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sn\n",
    "from colored import fg, bg, attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = 100\n",
    "MAX_SENTS = 15\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 200\n",
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "data_dir = 'data/'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "data1 = 'data/labeledTrainData.tsv'\n",
    "data2 = 'data/imdb_master.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning_Rate = 0.0002\n",
    "\n",
    "# Learning_Rate_Mode = 'SGD'\n",
    "# Learning_Rate_Mode = 'Amsgrad'\n",
    "Learning_Rate_Mode = 'Adam'\n",
    "# Learning_Rate_Mode = 'Adadelta'    \n",
    "    \n",
    "    \n",
    "SEQ_LEN = 100  # magic number - length to truncate sequences of words\n",
    "lstm_dim = 100\n",
    "dense_dim = 20\n",
    "dense_dropout = 0.2\n",
    "nb_classes = 2\n",
    "epoch = 10\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imdb data 불러오기 + 데이타 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                             review\n",
       "0          1  With all this stuff going down at the moment w...\n",
       "1          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2          0  The film starts with a manager (Nicholas Bell)...\n",
       "3          0  It must be assumed that those who praised this...\n",
       "4          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imdb 1, labeledTrainData.tsv\n",
    "data_1 = pd.read_csv( data1 , delimiter='\\t')\n",
    "print(data_1.shape)\n",
    "data_1 = data_1.drop(['id'], axis=1)\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Once again Mr. Costner has dragged out a movie...          0\n",
       "1  This is an example of why the majority of acti...          0\n",
       "2  First of all I hate those moronic rappers, who...          0\n",
       "3  Not even the Beatles could write songs everyon...          0\n",
       "4  Brass pictures (movies is not a fitting word f...          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imdb 2, imdb_master.csv\n",
    "data_2 = pd.read_csv( data2 ,encoding=\"latin-1\")\n",
    "data_2 = data_2.drop(['Unnamed: 0','type','file'],axis=1)\n",
    "data_2.columns = [\"review\",\"sentiment\"]\n",
    "data_2 = data_2[data_2.sentiment != 'unsup']\n",
    "data_2['sentiment'] = data_2['sentiment'].map({'pos': 1, 'neg': 0})\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  With all this stuff going down at the moment w...          1\n",
       "1  \\The Classic War of the Worlds\\\" by Timothy Hi...          1\n",
       "2  The film starts with a manager (Nicholas Bell)...          0\n",
       "3  It must be assumed that those who praised this...          0\n",
       "4  Superbly trashy and wondrously unpretentious 8...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 데이타 합치기\n",
    "data = pd.concat([data_1, data_2], sort=True).reset_index(drop=True, )\n",
    "data_copy = data\n",
    "print(data_copy.shape)\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Processed_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>1</td>\n",
       "      <td>stuff go moment mj ive start listen music watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>classic war world timothy hines entertain film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>0</td>\n",
       "      <td>film start manager nicholas bell give welcome ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  With all this stuff going down at the moment w...          1   \n",
       "1  \\The Classic War of the Worlds\\\" by Timothy Hi...          1   \n",
       "2  The film starts with a manager (Nicholas Bell)...          0   \n",
       "\n",
       "                                   Processed_Reviews  \n",
       "0  stuff go moment mj ive start listen music watc...  \n",
       "1  classic war world timothy hines entertain film...  \n",
       "2  film start manager nicholas bell give welcome ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 자연어처리, 전처리\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "# stopword, lemmatizer 불러오기\n",
    "stop_words = set(stopwords.words(\"english\")) \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "# \n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
    "    text = re.sub(r'<br />','',text, re.UNICODE)\n",
    "    text = re.sub(r'â','',text, re.UNICODE)\n",
    "    text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")] # token 단위 lemmati\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text] # 동사 lemmati\n",
    "    text = [word for word in text if not word in stop_words]  #stopword 없애고\n",
    "    text = \" \".join(text)  # 뛰어쓰기추가\n",
    "    return text\n",
    "\n",
    "data_copy['Processed_Reviews'] = data_copy.review.apply(lambda x: clean_text(x))\n",
    "print(data_copy.shape)\n",
    "data_copy[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/go/.local/lib/python3.6/site-packages/keras_preprocessing/text.py:177: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 15, 100)\n"
     ]
    }
   ],
   "source": [
    "reviews = []\n",
    "labels  = []\n",
    "texts   = []\n",
    "\n",
    "for idx in range(data_copy.review.shape[0]):\n",
    "    text = data_copy.review[idx]\n",
    "#     text = text.get_text().encode('ascii', 'ignore')\n",
    "#     text = clean_str(text)\n",
    "    text = clean_text(text)   # 캐글 전처리기 사용\n",
    "    texts.append(text)\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    reviews.append(sentences)\n",
    "\n",
    "    labels.append(data_copy.sentiment[idx])\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# text가 여러 문장으로 되어있는 review 이다. 그러므로 document지\n",
    "# 입력데이타 : [ N , 최대문장수, 최대문장길이]\n",
    "data = np.zeros((len(texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 160166 unique tokens.\n",
      "Shape of data tensor: (75000, 15, 100)\n",
      "Shape of label tensor: (75000, 2)\n",
      "Number of positive and negative reviews in traing and validation set\n",
      "[29934. 30066.]\n",
      "[7566. 7434.]\n",
      "x_train:  (60000, 15, 100)\n",
      "y_train:  (60000, 2)\n",
      "x_val  :  (15000, 15, 100)\n",
      "y_val  :  (15000, 2)\n"
     ]
    }
   ],
   "source": [
    "for i, sentences in enumerate(reviews):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if 'â' not in word:\n",
    "                    try:\n",
    "                        if k < MAX_SENT_LENGTH and tokenizer.word_index[word] < MAX_NB_WORDS:\n",
    "                            data[i, j, k] = tokenizer.word_index[word]\n",
    "                            k = k + 1\n",
    "                    except:\n",
    "                        print(word)\n",
    "                        print(sentences)\n",
    "                \n",
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "print('Number of positive and negative reviews in traing and validation set')\n",
    "print(y_train.sum(axis=0))\n",
    "print(y_val.sum(axis=0))\n",
    "\n",
    "print('x_train: ', x_train.shape)\n",
    "print('y_train: ', y_train.shape)\n",
    "print('x_val  : ', x_val.shape)\n",
    "print('y_val  : ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "GLOVE_DIR = 'glove'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.200d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Total %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "\n",
    "# building Hierachical Attention network\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "# 입력 : 총 단어 갯수, 103051\n",
    "# 출력 : EMBEDDING_DIM(200)\n",
    "# embedding_matrix = (103052, 200)\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SENT_LENGTH,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "def highlight(c, power):\n",
    "    if power >= 0.5:\n",
    "        print('{}{}{}{}'.format(bg(160), attr(1), c, attr(0)), end='')\n",
    "    elif power >= 0.4:\n",
    "        print('{}{}{}{}'.format(bg(196), attr(1), c, attr(0)), end='')\n",
    "    elif power >= 0.3:\n",
    "        print('{}{}{}{}'.format(bg(210), attr(1), c, attr(0)), end='')\n",
    "    elif power >= 0.2:\n",
    "        print('{}{}{}{}'.format(bg(217), attr(1), c, attr(0)), end='')\n",
    "    elif power >= 0.1:\n",
    "        print('{}{}{}{}'.format(bg(224), attr(1), c, attr(0)), end='')\n",
    "    elif power > 0.0:\n",
    "        print('{}{}{}{}'.format(bg(225), attr(1), c, attr(0)), end='')\n",
    "    else:\n",
    "        print(c, end='')\n",
    "        \n",
    "# visualize\n",
    "def highlight_normalize(c, power, power_min, power_max):\n",
    "    # 글자, power, 그 파워의 최소값, 최대값\n",
    "    # 최대, 최소값으로 0~1 normalize\n",
    "    power = (power - power_min) / (power_max - power_min)\n",
    "    \n",
    "    if power >= 0.9:\n",
    "        print('{}{}{}{}'.format(bg(160), attr(1), c, attr(0)), end='')\n",
    "    elif power >= 0.8:\n",
    "        print('{}{}{}{}'.format(bg(196), attr(1), c, attr(0)), end='')\n",
    "    elif power >= 0.6:\n",
    "        print('{}{}{}{}'.format(bg(210), attr(1), c, attr(0)), end='')\n",
    "    elif power >= 0.4:\n",
    "        print('{}{}{}{}'.format(bg(217), attr(1), c, attr(0)), end='')\n",
    "    elif power >= 0.2:\n",
    "        print('{}{}{}{}'.format(bg(224), attr(1), c, attr(0)), end='')\n",
    "    elif power > 0.0:\n",
    "        print('{}{}{}{}'.format(bg(225), attr(1), c, attr(0)), end='')\n",
    "    else:\n",
    "        print(c, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    Attention operation, with a context/query vector, for temporal data.\n",
    "    Supports Masking.\n",
    "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
    "    \"Hierarchical Attention Networks for Document Classification\"\n",
    "    by using a context vector to assist the attention\n",
    "    # Input shape\n",
    "        3D tensor with shape: `(samples, steps, features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(samples, features)`.\n",
    "    How to use:\n",
    "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
    "    The dimensions are inferred based on the output shape of the RNN.\n",
    "    Note: The layer has been tested with Keras 2.0.6\n",
    "    Example:\n",
    "        model.add(LSTM(64, return_sequences=True))\n",
    "        model.add(AttentionWithContext())\n",
    "        # next add a Dense layer (for classification/regression) or whatever...\n",
    "    \"\"\"\n",
    "#     def __init__(self, attention_dim, **kwargs):\n",
    "    def __init__(self, **kwargs):\n",
    "#         self.attention_dim = attention_dim\n",
    "\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        \n",
    "        self.W = self.add_weight(name='Attention_Weight',\n",
    "                                 shape=(input_shape[-1], input_shape[-1]),\n",
    "                                 initializer=self.init,\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='Attention_Bias',\n",
    "                                 shape=(input_shape[-1], ),\n",
    "                                 initializer=self.init,\n",
    "                                 trainable=True)\n",
    "        self.u = self.add_weight(name='Attention_Context_Vector',\n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer=self.init,\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "    \n",
    "    def call(self, x):\n",
    "        # refer to the original paper\n",
    "        # link: https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf\n",
    "        \n",
    "        # RNN 구조를 거쳐서 나온 hidden states (x)에 single layer perceptron (tanh activation)\n",
    "        # 적용하여 나온 벡터가 uit \n",
    "        u_it = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        \n",
    "        # uit와 uw (혹은 us) 간의 similarity를 attention으로 사용\n",
    "        # softmax를 통해 attention 값을 확률 분포로 만듬\n",
    "        a_it = K.dot(u_it, self.u)\n",
    "        a_it = K.squeeze(a_it, -1)\n",
    "        a_it = K.softmax(a_it)\n",
    "        \n",
    "        return a_it\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word-level attention 적용하기 (for sentence representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"attention_layer_1/Softmax:0\", shape=(?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# first, build a sentence encoder\n",
    "sentence_input = Input(shape=(MAX_SENT_LENGTH, ), dtype='int32')\n",
    "embedded_sentence = embedding_layer(sentence_input)\n",
    "# [?,?,200]\n",
    "bilstm_sentence = Bidirectional(LSTM(lstm_dim, return_sequences=True))(embedded_sentence)\n",
    "\n",
    "# word attention computation, [?,200]\n",
    "# word_attention = AttentionWithContext()(bilstm_sentence)\n",
    "word_attention = AttentionLayer()(bilstm_sentence)\n",
    "print(word_attention)\n",
    "\n",
    "# word attention application, [?,200, 200]\n",
    "# hidden states의 출력에 맞게 scalar를 반복해 (lstm_dim * 2) 크기로 만듬\n",
    "repeated_word_attention = RepeatVector(lstm_dim * 2)(word_attention)\n",
    "# Permute 레이어를 사용해 Multiply가 가능하도록 차원 수정, 곱하기 위하여\n",
    "# [MAX_SENTENCE_LENGTH, lstm_dim * 2] -> [lstm_dim * 2, MAX_SENTENCE_LENGTH] \n",
    "repeated_word_attention = Permute([2, 1])(repeated_word_attention)\n",
    "\n",
    "# compute sentence representation as the weighted sum of word representations\n",
    "# 곱하고\n",
    "sentence_representation = Multiply()([bilstm_sentence, repeated_word_attention])\n",
    "# weighted-sum과정, weighting 해주고 summation, 펼쳐서 수행\n",
    "sentence_representation = Lambda(lambda x: K.sum(x, axis=1))(sentence_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentence-attention 적용하기 (for document representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder = Model(inputs=[sentence_input], \n",
    "                         outputs=[sentence_representation])\n",
    "\n",
    "# then, build a document encoder\n",
    "document_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "# 입력이 document_input 이므로, sentence 입력으로 바꾸기 위하여\n",
    "embedded_document = TimeDistributed(sentence_encoder)(document_input)\n",
    "bilstm_document = Bidirectional(LSTM(lstm_dim, return_sequences=True))(embedded_document)\n",
    "\n",
    "# sentence attention computation\n",
    "sentence_attention = AttentionLayer()(bilstm_document)\n",
    "\n",
    "# sentence attention application\n",
    "repeated_sentence_attention = RepeatVector(lstm_dim * 2)(sentence_attention)\n",
    "repeated_sentence_attention = Permute([2, 1])(repeated_sentence_attention)\n",
    "\n",
    "# compute document representation as the weighted sum of sentence representations\n",
    "document_representation = Multiply()([bilstm_document, repeated_sentence_attention])\n",
    "document_representation = Lambda(lambda x: K.sum(x, axis=1))(document_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiment classification 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally, add fc layers for classification\n",
    "hidden = BatchNormalization()(document_representation)\n",
    "hidden = Dense(dense_dim)(hidden)\n",
    "hidden = LeakyReLU(alpha=0.1)(hidden)\n",
    "hidden = Dropout(dense_dropout)(hidden)\n",
    "\n",
    "pred_sentiment = Dense(nb_classes, activation='softmax')(hidden)\n",
    "\n",
    "model = Model(inputs=[document_input],\n",
    "            outputs=[pred_sentiment])\n",
    "\n",
    "# compile\n",
    "if   Learning_Rate_Mode == 'SGD':\n",
    "    opt = SGD(lr=Learning_Rate, momentum=0.9, decay=1e-6)\n",
    "elif Learning_Rate_Mode == 'Amsgrad':\n",
    "    opt = Adam(lr=Learning_Rate, amsgrad=True)\n",
    "elif Learning_Rate_Mode == 'Adam':\n",
    "    opt = Adam(lr=Learning_Rate)\n",
    "elif Learning_Rate_Mode == 'Adadelta':    \n",
    "    opt = Adadelta(lr=Learning_Rate)\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 200)     32033400    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 100, 200)     240800      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_1 (AttentionLay (None, 100)          40400       bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 200, 100)     0           attention_layer_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 100, 200)     0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 100, 200)     0           bidirectional_1[0][0]            \n",
      "                                                                 permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 200)          0           multiply_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 32,314,600\n",
      "Trainable params: 32,314,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sentence_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 15, 100)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 15, 200)      32314600    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 15, 200)      240800      time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer_2 (AttentionLay (None, 15)           40400       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 200, 15)      0           attention_layer_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 15, 200)      0           repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 15, 200)      0           bidirectional_2[0][0]            \n",
      "                                                                 permute_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 200)          0           multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200)          800         lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20)           4020        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 20)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 20)           0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            42          dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 32,600,662\n",
      "Trainable params: 32,600,262\n",
      "Non-trainable params: 400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck_dir = 'models/'\n",
    "os.makedirs(ck_dir, exist_ok=True)\n",
    "ck_path = ck_dir + 'model.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(ck_path,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "early_stopping = EarlyStopping(patience = 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - Hierachical attention network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/go/anaconda3/envs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 494s 8ms/step - loss: 0.3699 - acc: 0.8349 - val_loss: 0.2730 - val_acc: 0.8905\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.2474 - acc: 0.9006 - val_loss: 0.2609 - val_acc: 0.8953\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.1862 - acc: 0.9299 - val_loss: 0.2398 - val_acc: 0.9024\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.1357 - acc: 0.9508 - val_loss: 0.2041 - val_acc: 0.9303\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0927 - acc: 0.9680 - val_loss: 0.2237 - val_acc: 0.9291\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 488s 8ms/step - loss: 0.0674 - acc: 0.9773 - val_loss: 0.2842 - val_acc: 0.9186\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0468 - acc: 0.9845 - val_loss: 0.3375 - val_acc: 0.9111\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 489s 8ms/step - loss: 0.0284 - acc: 0.9907 - val_loss: 0.3088 - val_acc: 0.9415\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0260 - acc: 0.9917 - val_loss: 0.3311 - val_acc: 0.9325\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0181 - acc: 0.9940 - val_loss: 0.3810 - val_acc: 0.9357\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0144 - acc: 0.9955 - val_loss: 0.3552 - val_acc: 0.9443\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0121 - acc: 0.9963 - val_loss: 0.3751 - val_acc: 0.9353\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0129 - acc: 0.9959 - val_loss: 0.3942 - val_acc: 0.9402\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0104 - acc: 0.9963 - val_loss: 0.3955 - val_acc: 0.9408\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0104 - acc: 0.9966 - val_loss: 0.3917 - val_acc: 0.9436\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.4134 - val_acc: 0.9455\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.4289 - val_acc: 0.9411\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.4663 - val_acc: 0.9387\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.4400 - val_acc: 0.9347\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.4502 - val_acc: 0.9411\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 488s 8ms/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.4514 - val_acc: 0.9446\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0048 - acc: 0.9985 - val_loss: 0.4384 - val_acc: 0.9435\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.4504 - val_acc: 0.9456\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.4340 - val_acc: 0.9388\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.4524 - val_acc: 0.9435\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 482s 8ms/step - loss: 0.0045 - acc: 0.9986 - val_loss: 0.5119 - val_acc: 0.9423\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.4790 - val_acc: 0.9429\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.4643 - val_acc: 0.9453\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.4919 - val_acc: 0.9421\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.5551 - val_acc: 0.9427\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.4877 - val_acc: 0.9423\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.5026 - val_acc: 0.9396\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.5127 - val_acc: 0.9441\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.4861 - val_acc: 0.9427\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.4962 - val_acc: 0.9433\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.5111 - val_acc: 0.9449\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.4978 - val_acc: 0.9442\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.4388 - val_acc: 0.9473\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 483s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.5686 - val_acc: 0.9458\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 483s 8ms/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.5002 - val_acc: 0.9430\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.5106 - val_acc: 0.9443\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.5677 - val_acc: 0.9446\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.6302 - val_acc: 0.9420\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.5481 - val_acc: 0.9424\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.5262 - val_acc: 0.9425\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0030 - acc: 0.9989 - val_loss: 0.5291 - val_acc: 0.9440\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.5112 - val_acc: 0.9428\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 8.4814e-04 - acc: 0.9998 - val_loss: 0.6186 - val_acc: 0.9419\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.5388 - val_acc: 0.9411\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.5288 - val_acc: 0.9405\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 488s 8ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.4713 - val_acc: 0.9435\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 483s 8ms/step - loss: 4.3615e-04 - acc: 1.0000 - val_loss: 0.6418 - val_acc: 0.9414\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.6764 - val_acc: 0.9350\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.5349 - val_acc: 0.9425\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.4762 - val_acc: 0.9437\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 487s 8ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.5323 - val_acc: 0.9427\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 483s 8ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.5082 - val_acc: 0.9441\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 6.2372e-04 - acc: 0.9999 - val_loss: 0.5956 - val_acc: 0.9429\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 487s 8ms/step - loss: 3.2791e-04 - acc: 1.0000 - val_loss: 0.6214 - val_acc: 0.9443\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.6495 - val_acc: 0.9401\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.5551 - val_acc: 0.9459\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.5734 - val_acc: 0.9438\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 483s 8ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.5914 - val_acc: 0.9434\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 3.3717e-04 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 0.9428\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 483s 8ms/step - loss: 2.8223e-04 - acc: 1.0000 - val_loss: 0.6681 - val_acc: 0.9435\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 2.8586e-04 - acc: 1.0000 - val_loss: 0.6885 - val_acc: 0.9441\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.5046 - val_acc: 0.9430\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.5538 - val_acc: 0.9437\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.5853 - val_acc: 0.9440\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 486s 8ms/step - loss: 6.9506e-04 - acc: 0.9998 - val_loss: 0.6152 - val_acc: 0.9427\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.5831 - val_acc: 0.9402\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 483s 8ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.6063 - val_acc: 0.9410\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 484s 8ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.5763 - val_acc: 0.9430\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 485s 8ms/step - loss: 6.2011e-04 - acc: 0.9999 - val_loss: 0.6269 - val_acc: 0.9450\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "print(\"model fitting - Hierachical attention network\")\n",
    "hist = model.fit( x_train, y_train, \n",
    "                  nb_epoch=epoch, \n",
    "                  batch_size=batch_size,\n",
    "                  shuffle=True,\n",
    "                  callbacks=[checkpoint, early_stopping],\n",
    "                  validation_data=(x_val, y_val)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation accuracy :  94.73 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델 학습 과정 표시하기\n",
    "print('Best validation accuracy : ', round(np.max(hist.history['val_acc'])*100,2), '%')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention 시각화하기\n",
    "HAN에서는 word-level attention과 sentence-level attention이 함께 쓰입니다. 이 attention들을 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 넛고, word_attention layer 출력, 근데 입력이 document 므로, TimeDistributed로 만들기\n",
    "word_attention_extractor = Model(inputs=[sentence_input],\n",
    "                                 outputs=[word_attention])\n",
    "\n",
    "word_attentions = TimeDistributed(word_attention_extractor)(document_input)\n",
    "\n",
    "# doc 입력으로 단어레벨, 문장레벨 어텐션 뽑기\n",
    "attention_extractor = Model(inputs=[document_input],\n",
    "                            outputs=[word_attentions, sentence_attention])\n",
    "# (N, 15, 100)\n",
    "attention_expamle = attention_extractor.predict(x_val[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word attention visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_rev_index = {}\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    word_rev_index[i] = word\n",
    "\n",
    "def sentiment_analysis(review): \n",
    "    sentences = tokenize.sent_tokenize(review)  # 문단->문장단위로 자르기\n",
    "    tokenized_sentences = tokenizer.texts_to_sequences(sentences)  # 벡터화\n",
    "    tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=MAX_SENT_LENGTH) # 문장 최대길이로 제로패딩, 앞쪽으로 0이 붙는다\n",
    "    pad_size = MAX_SENTS - tokenized_sentences.shape[0]  # 15 - 6 = 9, 문장단위로는 9번 패딩해야한다\n",
    "\n",
    "    # tokenized_sentences : [15 , 100]\n",
    "    if pad_size <= 0:\n",
    "        tokenized_sentences = tokenized_sentences[:MAX_SENTS]  # 최대 문장수보다 크면 MAX_SENTS 만큼 자르고\n",
    "    else:\n",
    "        tokenized_sentences = np.pad(\n",
    "            tokenized_sentences, ((0, pad_size), (0, 0)),\n",
    "            mode='constant', constant_values=0\n",
    "        )  # 그렇지 않으면 죄다 0으로 패딩\n",
    "    tokenized_sentences_input = np.asarray([tokenized_sentences])  # list를 np array로 변환하여 입력하기 위해\n",
    "\n",
    "    # 단어기준, 문장기준 어텐션 가져오기, np.asarray를 이용해서 list를 np array로 만들어서 너어준다\n",
    "    pred_word_attention    = attention_extractor.predict(tokenized_sentences_input)[0]  # [0] : word attention만 가져오기, (1, 15, 100)\n",
    "    pred_sentence_attention= attention_extractor.predict(tokenized_sentences_input)[1]  # [1] : sentence attention만 가져오기, (1, 15)\n",
    "\n",
    "    # 문장단위 어탠션 nomalize, [0.30764675, 0.27119225, 0.17760307, 0.11542551, 0.07580608, 0.05232629]\n",
    "    real_sentence_attention = pred_sentence_attention[0][:-pad_size]\n",
    "    real_sentence_attention = real_sentence_attention / (np.sum(real_sentence_attention))  # normalize\n",
    "    real_sentence_attention\n",
    "    # 문장단위 어텐션 visualize\n",
    "    print('Sentence attention visualize\\n')\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        print(round(real_sentence_attention[i],2),': ' , end='')\n",
    "        for j in sentence:\n",
    "            highlight_normalize(j, real_sentence_attention[i], np.min(real_sentence_attention), np.max(real_sentence_attention) )\n",
    "        print()\n",
    "\n",
    "    # 단어단위 어텐션 visualize\n",
    "    print('\\nword attention visualize\\n')\n",
    "    for i, sentence in enumerate(tokenized_sentences[:-pad_size]):\n",
    "        # word_rev_index로 idx -> 실제 단어, 0제외\n",
    "        words = [word_rev_index[word_id] for word_id in sentence if word_id != 0][:50]\n",
    "        pred_att = np.asarray(pred_word_attention[0][i][::-1][:len(words)][::-1])  # [::-1]로 순서 뒤집고, 단어수만큼만 짜르고, 다시 순서 뒤집어서 단어만 나오도록\n",
    "\n",
    "        for j, word in enumerate(words):\n",
    "            highlight_normalize(word, pred_att[j], np.min(pred_att), np.max(pred_att))\n",
    "            print(' ',end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Processed_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>1</td>\n",
       "      <td>stuff go moment mj ive start listen music watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>classic war world timothy hines entertain film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>0</td>\n",
       "      <td>film start manager nicholas bell give welcome ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  With all this stuff going down at the moment w...          1   \n",
       "1  \\The Classic War of the Worlds\\\" by Timothy Hi...          1   \n",
       "2  The film starts with a manager (Nicholas Bell)...          0   \n",
       "\n",
       "                                   Processed_Reviews  \n",
       "0  stuff go moment mj ive start listen music watc...  \n",
       "1  classic war world timothy hines entertain film...  \n",
       "2  film start manager nicholas bell give welcome ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence attention visualize\n",
      "\n",
      "0.92 : \u001b[48;5;160m\u001b[1mD\u001b[0m\u001b[48;5;160m\u001b[1me\u001b[0m\u001b[48;5;160m\u001b[1ml\u001b[0m\u001b[48;5;160m\u001b[1mi\u001b[0m\u001b[48;5;160m\u001b[1mc\u001b[0m\u001b[48;5;160m\u001b[1mi\u001b[0m\u001b[48;5;160m\u001b[1mo\u001b[0m\u001b[48;5;160m\u001b[1mu\u001b[0m\u001b[48;5;160m\u001b[1ms\u001b[0m\u001b[48;5;160m\u001b[1m \u001b[0m\u001b[48;5;160m\u001b[1mh\u001b[0m\u001b[48;5;160m\u001b[1me\u001b[0m\u001b[48;5;160m\u001b[1ma\u001b[0m\u001b[48;5;160m\u001b[1ml\u001b[0m\u001b[48;5;160m\u001b[1mt\u001b[0m\u001b[48;5;160m\u001b[1mh\u001b[0m\u001b[48;5;160m\u001b[1my\u001b[0m\u001b[48;5;160m\u001b[1m \u001b[0m\u001b[48;5;160m\u001b[1mf\u001b[0m\u001b[48;5;160m\u001b[1mo\u001b[0m\u001b[48;5;160m\u001b[1mo\u001b[0m\u001b[48;5;160m\u001b[1md\u001b[0m\u001b[48;5;160m\u001b[1m.\u001b[0m\n",
      "0.05 : \u001b[48;5;225m\u001b[1mT\u001b[0m\u001b[48;5;225m\u001b[1mh\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1ms\u001b[0m\u001b[48;5;225m\u001b[1mt\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1ma\u001b[0m\u001b[48;5;225m\u001b[1mk\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1mi\u001b[0m\u001b[48;5;225m\u001b[1ms\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1ma\u001b[0m\u001b[48;5;225m\u001b[1mm\u001b[0m\u001b[48;5;225m\u001b[1ma\u001b[0m\u001b[48;5;225m\u001b[1mz\u001b[0m\u001b[48;5;225m\u001b[1mi\u001b[0m\u001b[48;5;225m\u001b[1mn\u001b[0m\u001b[48;5;225m\u001b[1mg\u001b[0m\u001b[48;5;225m\u001b[1m.\u001b[0m\n",
      "0.01 : \u001b[48;5;225m\u001b[1mF\u001b[0m\u001b[48;5;225m\u001b[1mi\u001b[0m\u001b[48;5;225m\u001b[1ms\u001b[0m\u001b[48;5;225m\u001b[1mh\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1ma\u001b[0m\u001b[48;5;225m\u001b[1mn\u001b[0m\u001b[48;5;225m\u001b[1md\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1mp\u001b[0m\u001b[48;5;225m\u001b[1mo\u001b[0m\u001b[48;5;225m\u001b[1mr\u001b[0m\u001b[48;5;225m\u001b[1mk\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1ma\u001b[0m\u001b[48;5;225m\u001b[1mr\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1ma\u001b[0m\u001b[48;5;225m\u001b[1mw\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1ms\u001b[0m\u001b[48;5;225m\u001b[1mo\u001b[0m\u001b[48;5;225m\u001b[1mm\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1mt\u001b[0m\u001b[48;5;225m\u001b[1mo\u001b[0m\u001b[48;5;225m\u001b[1mo\u001b[0m\u001b[48;5;225m\u001b[1m.\u001b[0m\n",
      "0.0 : \u001b[48;5;225m\u001b[1mS\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1mr\u001b[0m\u001b[48;5;225m\u001b[1mv\u001b[0m\u001b[48;5;225m\u001b[1mi\u001b[0m\u001b[48;5;225m\u001b[1mc\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1mi\u001b[0m\u001b[48;5;225m\u001b[1ms\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1ma\u001b[0m\u001b[48;5;225m\u001b[1mb\u001b[0m\u001b[48;5;225m\u001b[1mo\u001b[0m\u001b[48;5;225m\u001b[1mv\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1ma\u001b[0m\u001b[48;5;225m\u001b[1mn\u001b[0m\u001b[48;5;225m\u001b[1md\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1mb\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1my\u001b[0m\u001b[48;5;225m\u001b[1mo\u001b[0m\u001b[48;5;225m\u001b[1mn\u001b[0m\u001b[48;5;225m\u001b[1md\u001b[0m\u001b[48;5;225m\u001b[1m.\u001b[0m\n",
      "0.0 : Not a bad thing to say about this place.\n",
      "0.01 : \u001b[48;5;225m\u001b[1mW\u001b[0m\u001b[48;5;225m\u001b[1mo\u001b[0m\u001b[48;5;225m\u001b[1mr\u001b[0m\u001b[48;5;225m\u001b[1mt\u001b[0m\u001b[48;5;225m\u001b[1mh\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1mv\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1mr\u001b[0m\u001b[48;5;225m\u001b[1my\u001b[0m\u001b[48;5;225m\u001b[1m \u001b[0m\u001b[48;5;225m\u001b[1mp\u001b[0m\u001b[48;5;225m\u001b[1me\u001b[0m\u001b[48;5;225m\u001b[1mn\u001b[0m\u001b[48;5;225m\u001b[1mn\u001b[0m\u001b[48;5;225m\u001b[1my\u001b[0m\u001b[48;5;225m\u001b[1m!\u001b[0m\n",
      "\n",
      "word attention visualize\n",
      "\n",
      "\u001b[48;5;160m\u001b[1mdelicious\u001b[0m \u001b[48;5;225m\u001b[1mhealthy\u001b[0m food \n",
      "\u001b[48;5;160m\u001b[1mthe\u001b[0m \u001b[48;5;217m\u001b[1msteak\u001b[0m is \u001b[48;5;224m\u001b[1mamazing\u001b[0m \n",
      "\u001b[48;5;224m\u001b[1mfish\u001b[0m \u001b[48;5;210m\u001b[1mand\u001b[0m \u001b[48;5;160m\u001b[1mpork\u001b[0m \u001b[48;5;225m\u001b[1mare\u001b[0m \u001b[48;5;210m\u001b[1mawesome\u001b[0m too \n",
      "\u001b[48;5;160m\u001b[1mservice\u001b[0m \u001b[48;5;225m\u001b[1mis\u001b[0m \u001b[48;5;225m\u001b[1mabove\u001b[0m and \u001b[48;5;225m\u001b[1mbeyond\u001b[0m \n",
      "\u001b[48;5;217m\u001b[1mnot\u001b[0m \u001b[48;5;224m\u001b[1ma\u001b[0m \u001b[48;5;210m\u001b[1mbad\u001b[0m \u001b[48;5;225m\u001b[1mthing\u001b[0m \u001b[48;5;225m\u001b[1mto\u001b[0m say \u001b[48;5;225m\u001b[1mabout\u001b[0m \u001b[48;5;160m\u001b[1mthis\u001b[0m \u001b[48;5;217m\u001b[1mplace\u001b[0m \n",
      "\u001b[48;5;160m\u001b[1mworth\u001b[0m every \u001b[48;5;225m\u001b[1mpenny\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "# for i in range(444, 449):\n",
    "#     review = []\n",
    "#     review = data_copy.review[i]\n",
    "#     if data_copy.sentiment[i] == 1:\n",
    "#         print('긍정', i)\n",
    "#     else:\n",
    "#         print('부정', i)\n",
    "    \n",
    "#     sentiment_analysis(review)\n",
    "#     print('\\n\\n\\n')\n",
    "sentiment_analysis(\"Delicious healthy food. The steak is amazing. Fish and pork are awesome too. Service is above and beyond. Not a bad thing to say about this place. Worth every penny!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 score 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 82s 5ms/step\n",
      "accuracy: [0.6269252490109956, 0.9449999999682108]\n",
      "F1-score: 0.9446791390062361\n",
      "Confusion matrix:\n",
      "[[7131  390]\n",
      " [ 435 7044]]\n"
     ]
    }
   ],
   "source": [
    "# F1 score & confusion matrix 구하기 위해서 [1,0] -> [True] 식으로 변환\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "prediction = model.predict(x_val)\n",
    "y_val = y_val\n",
    "y_pred = (prediction > 0.5)\n",
    "y_val_temp = (y_val > 0.5)\n",
    "\n",
    "y_pred = []\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i][1] > 0.5:\n",
    "        y_pred.append(True)\n",
    "    else:\n",
    "        y_pred.append(False)\n",
    "        \n",
    "y_val_temp = []\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i][1] == 1:\n",
    "        y_val_temp.append(True)\n",
    "    else:\n",
    "        y_val_temp.append(False)\n",
    "\n",
    "print('accuracy: {0}'.format(model.evaluate(x_val, y_val)))\n",
    "print('F1-score: {0}'.format(f1_score(y_pred, y_val_temp)))\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_pred, y_val_temp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
